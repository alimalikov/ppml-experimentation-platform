"""
Multi-layer Perceptron Regressor Plugin
======================================

This is the main plugin file for the MLP Regressor algorithm, providing a complete
neural network solution with advanced analysis, visualization, and optimization capabilities.

The plugin integrates:
- MLPCore: Core neural network implementation
- MLPAnalysis: Advanced analysis and optimization
- MLPDisplay: Comprehensive visualization suite

Features:
- Professional neural network training
- Hyperparameter optimization
- Architecture analysis and recommendations
- Interactive visualizations and dashboards
- Production deployment assessment
- Comprehensive reporting

Author: Bachelor Thesis Project
Date: June 2025
Version: 2.0
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Optional, List, Tuple, Union
import logging
import warnings
from pathlib import Path
import json
import time
from datetime import datetime

# Core ML imports
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Import for plugin system - will be auto-fixed during save
try:
    from src.ml_plugins.base_ml_plugin import MLPlugin
except ImportError:
    # Fallback for testing
    import sys
    import os
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
    sys.path.append(project_root)
    from src.ml_plugins.base_ml_plugin import MLPlugin

# Import the three core components
try:
    from src.ml_plugins.algorithms.mlp_regressor.mlp_core import MLPCore
    from src.ml_plugins.algorithms.mlp_regressor.mlp_analysis import MLPAnalysis
    from src.ml_plugins.algorithms.mlp_regressor.mlp_display import MLPDisplay
except ImportError as e:
    # Fallback for different import structures
    try:
        from mlp_regressor.mlp_core import MLPCore
        from mlp_regressor.mlp_analysis import MLPAnalysis
        from mlp_regressor.mlp_display import MLPDisplay
    except ImportError:
        raise ImportError(f"Could not import MLP components: {e}")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore', category=UserWarning)


class MLPRegressorPlugin(MLPlugin):
    """
    Multi-layer Perceptron Regressor Plugin
    
    A comprehensive neural network plugin that provides advanced training,
    analysis, and visualization capabilities for regression tasks.
    
    This plugin combines three main components:
    - Core neural network implementation (MLPCore)
    - Advanced analysis and optimization (MLPAnalysis)
    - Comprehensive visualization suite (MLPDisplay)
    """
    
    def __init__(self, 
                 hidden_layer_sizes: Tuple[int, ...] = (100,),
                 activation: str = 'relu',
                 solver: str = 'adam',
                 alpha: float = 0.0001,
                 learning_rate_init: float = 0.001,
                 max_iter: int = 200,
                 random_state: Optional[int] = None,
                 enable_analysis: bool = True,
                 enable_display: bool = True):
        """
        Initialize the MLP Regressor Plugin.
        
        Parameters:
        -----------
        hidden_layer_sizes : tuple, default=(100,)
            Number of neurons in each hidden layer
        activation : str, default='relu'
            Activation function for hidden layers
        solver : str, default='adam'
            Optimization algorithm
        alpha : float, default=0.0001
            L2 regularization strength
        learning_rate_init : float, default=0.001
            Initial learning rate
        max_iter : int, default=200
            Maximum number of iterations
        random_state : int, optional
            Random state for reproducibility
        enable_analysis : bool, default=True
            Enable advanced analysis features
        enable_display : bool, default=True
            Enable visualization features
        """
        super().__init__()
        
        # Extract plugin configuration
        self.config = {
            'hidden_layer_sizes': hidden_layer_sizes,
            'activation': activation,
            'solver': solver,
            'alpha': alpha,
            'learning_rate_init': learning_rate_init,
            'max_iter': max_iter,
            'random_state': random_state,
            'early_stopping': False,
            'validation_fraction': 0.1,
            'n_iter_no_change': 10,
            'tol': 1e-4,
            'enable_analysis': enable_analysis,
            'enable_display': enable_display,
            'auto_optimize': False,
            'optimization_budget': 'medium',
            'save_artifacts': True,
            'artifact_dir': './mlp_artifacts'
        }
        
        # Initialize core components
        self.mlp_core = None
        self.mlp_analysis = None
        self.mlp_display = None
        
        # Plugin state
        self.is_trained = False
        self.training_results = {}
        self.analysis_results = {}
        self.last_predictions = None
        self.training_history = []
        
        # Plugin metadata - following MLPlugin pattern
        self._plugin_info = {
            'name': 'mlp_regressor',
            'display_name': 'Multi-layer Perceptron Regressor',
            'version': '2.0',
            'algorithm_type': 'Neural Network',
            'task_type': 'Regression',
            'category': 'neural_network',
            'description': 'Advanced Multi-layer Perceptron for regression tasks',
            'author': 'Bachelor Thesis Project',
            'date_created': '2025-06-08'
        }
        
        # Required capability flags
        self._supports_classification = False
        self._supports_regression = True
        self._min_samples_required = 10
        
        logger.info(f"üß† {self._plugin_info['display_name']} v{self._plugin_info['version']} initialized")
    
    # ==================== REQUIRED ABSTRACT METHODS ====================
    
    def get_name(self) -> str:
        """Get the algorithm name (Required by MLPlugin)."""
        return "Multi-layer Perceptron Regressor"
    
    def get_description(self) -> str:
        """Get the algorithm description (Required by MLPlugin)."""
        return ("A neural network regression algorithm that uses multiple layers of neurons "
                "with various activation functions and optimization algorithms for complex "
                "pattern recognition and non-linear function approximation.")
    
    def create_model_instance(self, hyperparameters: Dict[str, Any]) -> 'MLPRegressorPlugin':
        """Create model instance with given hyperparameters (Required by MLPlugin)."""
        return MLPRegressorPlugin(
            hidden_layer_sizes=hyperparameters.get("hidden_layer_sizes", self.config['hidden_layer_sizes']),
            activation=hyperparameters.get("activation", self.config['activation']),
            solver=hyperparameters.get("solver", self.config['solver']),
            alpha=hyperparameters.get("alpha", self.config['alpha']),
            learning_rate_init=hyperparameters.get("learning_rate_init", self.config['learning_rate_init']),
            max_iter=hyperparameters.get("max_iter", self.config['max_iter']),
            random_state=hyperparameters.get("random_state", self.config['random_state']),
            enable_analysis=hyperparameters.get("enable_analysis", self.config['enable_analysis']),
            enable_display=hyperparameters.get("enable_display", self.config['enable_display'])
        )
    
    def get_hyperparameter_config(self, key_prefix: str = "") -> Dict[str, Any]:
        """Get hyperparameter configuration for UI (Required by MLPlugin)."""
        try:
            import streamlit as st
            
            st.sidebar.subheader(f"{self.get_name()} Configuration")
            
            # Create tabs for different configuration sections - NOW WITH STRATEGY TAB!
            basic_tab, advanced_tab, strategy_tab, analysis_tab, viz_tab = st.sidebar.tabs([
                "üìä Basic", "‚öôÔ∏è Advanced", "üéØ Strategy", "üîç Analysis", "üìà Visualization"
            ])
            
            config = {}
            
            # ==================== BASIC PARAMETERS TAB ====================
            with basic_tab:
                st.markdown("**Core Neural Network Parameters**")
                
                # Hidden layer sizes
                layers_text = st.text_input(
                    "Hidden Layer Sizes:",
                    value=str(self.config['hidden_layer_sizes']).strip('()'),
                    help="Comma-separated layer sizes, e.g., '100,50' for two layers",
                    key=f"{key_prefix}_hidden_layers"
                )
                
                try:
                    if ',' in layers_text:
                        config["hidden_layer_sizes"] = tuple(map(int, layers_text.split(',')))
                    else:
                        config["hidden_layer_sizes"] = (int(layers_text),)
                except:
                    config["hidden_layer_sizes"] = (100,)
                
                # Activation function
                config["activation"] = st.selectbox(
                    "Activation Function:",
                    options=['relu', 'tanh', 'logistic', 'identity'],
                    index=['relu', 'tanh', 'logistic', 'identity'].index(self.config['activation']),
                    help="Activation function for hidden layers",
                    key=f"{key_prefix}_activation"
                )
                
                # Solver
                config["solver"] = st.selectbox(
                    "Solver:",
                    options=['adam', 'lbfgs', 'sgd'],
                    index=['adam', 'lbfgs', 'sgd'].index(self.config['solver']),
                    help="Optimization algorithm",
                    key=f"{key_prefix}_solver"
                )
                
                # Alpha (regularization)
                config["alpha"] = st.number_input(
                    "Alpha (L2 Regularization):",
                    value=float(self.config['alpha']),
                    min_value=1e-7,
                    max_value=1e-1,
                    format="%.6f",
                    help="L2 regularization strength",
                    key=f"{key_prefix}_alpha"
                )
                
                # Learning rate
                config["learning_rate_init"] = st.number_input(
                    "Initial Learning Rate:",
                    value=float(self.config['learning_rate_init']),
                    min_value=1e-5,
                    max_value=1.0,
                    format="%.6f",
                    help="Initial learning rate for optimization",
                    key=f"{key_prefix}_learning_rate"
                )
                
                # Max iterations
                config["max_iter"] = st.number_input(
                    "Max Iterations:",
                    value=int(self.config['max_iter']),
                    min_value=50,
                    max_value=2000,
                    step=50,
                    help="Maximum number of training iterations",
                    key=f"{key_prefix}_max_iter"
                )
            
            # ==================== ADVANCED PARAMETERS TAB ====================
            with advanced_tab:
                st.markdown("**Advanced Training Settings**")
                
                # Early stopping
                config["early_stopping"] = st.checkbox(
                    "Early Stopping",
                    value=self.config.get('early_stopping', False),
                    help="Stop training when validation score stops improving",
                    key=f"{key_prefix}_early_stopping"
                )
                
                if config["early_stopping"]:
                    config["validation_fraction"] = st.slider(
                        "Validation Fraction:",
                        min_value=0.1,
                        max_value=0.3,
                        value=self.config.get('validation_fraction', 0.1),
                        step=0.05,
                        help="Fraction of training data for validation",
                        key=f"{key_prefix}_val_fraction"
                    )
                    
                    config["n_iter_no_change"] = st.number_input(
                        "No Change Iterations:",
                        value=int(self.config.get('n_iter_no_change', 10)),
                        min_value=5,
                        max_value=50,
                        help="Max iterations without improvement",
                        key=f"{key_prefix}_no_change"
                    )
                
                # Tolerance
                config["tol"] = st.number_input(
                    "Tolerance:",
                    value=float(self.config.get('tol', 1e-4)),
                    min_value=1e-6,
                    max_value=1e-2,
                    format="%.6f",
                    help="Tolerance for optimization",
                    key=f"{key_prefix}_tolerance"
                )
                
                # Random state
                config["random_state"] = st.number_input(
                    "Random State:",
                    value=self.config['random_state'] if self.config['random_state'] is not None else 42,
                    min_value=0,
                    max_value=9999,
                    step=1,
                    help="Random state for reproducibility",
                    key=f"{key_prefix}_random_state"
                )
                
                # Auto optimization
                config["auto_optimize"] = st.checkbox(
                    "Auto Optimize",
                    value=self.config.get('auto_optimize', False),
                    help="Automatically optimize hyperparameters",
                    key=f"{key_prefix}_auto_optimize"
                )
                
                if config["auto_optimize"]:
                    config["optimization_budget"] = st.selectbox(
                        "Optimization Budget:",
                        options=['low', 'medium', 'high'],
                        index=['low', 'medium', 'high'].index(self.config.get('optimization_budget', 'medium')),
                        help="Computational budget for optimization",
                        key=f"{key_prefix}_opt_budget"
                    )
            
            # ==================== üéØ NEW STRATEGY TAB ====================
            with strategy_tab:
                st.markdown("**üéØ Neural Network Strategy & Recommendations**")
                
                # Strategy Profile Selection
                st.markdown("**Strategy Profile**")
                strategy_profile = st.selectbox(
                    "Select Strategy Profile:",
                    options=[
                        'conservative', 'balanced', 'aggressive', 
                        'exploration', 'production', 'research', 'custom'
                    ],
                    index=0,
                    help="Pre-configured strategy profiles for different use cases",
                    key=f"{key_prefix}_strategy_profile"
                )
                
                config["strategy_profile"] = strategy_profile
                
                # Display strategy recommendations based on profile
                strategy_recommendations = self._get_strategy_recommendations(strategy_profile)
                
                with st.expander("üìã Strategy Profile Details", expanded=True):
                    st.markdown(f"**{strategy_recommendations['name']}**")
                    st.markdown(strategy_recommendations['description'])
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**Recommended For:**")
                        for item in strategy_recommendations['recommended_for']:
                            st.markdown(f"‚Ä¢ {item}")
                    
                    with col2:
                        st.markdown("**Key Features:**")
                        for feature in strategy_recommendations['features']:
                            st.markdown(f"‚Ä¢ {feature}")
                
                st.markdown("---")
                
                # Training Strategy Configuration
                st.markdown("**üèãÔ∏è Training Strategy**")
                
                config["training_strategy"] = st.selectbox(
                    "Training Approach:",
                    options=['standard', 'iterative_improvement', 'multi_stage', 'ensemble_preparation'],
                    index=0,
                    help="Overall training strategy approach",
                    key=f"{key_prefix}_training_strategy"
                )
                
                config["convergence_strategy"] = st.selectbox(
                    "Convergence Strategy:",
                    options=['patience_based', 'improvement_threshold', 'hybrid', 'time_bounded'],
                    index=0,
                    help="Strategy for determining training completion",
                    key=f"{key_prefix}_convergence_strategy"
                )
                
                config["overfitting_prevention"] = st.multiselect(
                    "Overfitting Prevention:",
                    options=[
                        'early_stopping', 'regularization', 'dropout_simulation', 
                        'validation_monitoring', 'cross_validation'
                    ],
                    default=['early_stopping', 'regularization'],
                    help="Select overfitting prevention strategies",
                    key=f"{key_prefix}_overfitting_prevention"
                )
                
                st.markdown("---")
                
                # Performance Strategy
                st.markdown("**üìä Performance Strategy**")
                
                config["performance_target"] = st.selectbox(
                    "Performance Target:",
                    options=['accuracy_focused', 'speed_focused', 'balanced', 'memory_efficient'],
                    index=2,
                    help="Primary performance optimization target",
                    key=f"{key_prefix}_performance_target"
                )
                
                config["quality_threshold"] = st.slider(
                    "Minimum Quality Threshold:",
                    min_value=0.1,
                    max_value=0.95,
                    value=0.7,
                    step=0.05,
                    help="Minimum acceptable model performance (R¬≤)",
                    key=f"{key_prefix}_quality_threshold"
                )
                
                config["robustness_testing"] = st.checkbox(
                    "Enable Robustness Testing",
                    value=True,
                    help="Test model stability and generalization",
                    key=f"{key_prefix}_robustness_testing"
                )
                
                st.markdown("---")
                
                # Architecture Strategy
                st.markdown("**üèóÔ∏è Architecture Strategy**")
                
                config["architecture_approach"] = st.selectbox(
                    "Architecture Approach:",
                    options=['manual', 'guided_search', 'automated_search', 'hybrid'],
                    index=1,
                    help="Approach for determining network architecture",
                    key=f"{key_prefix}_architecture_approach"
                )
                
                if config["architecture_approach"] in ['guided_search', 'automated_search', 'hybrid']:
                    config["search_space"] = st.multiselect(
                        "Search Space:",
                        options=[
                            'layer_count', 'layer_sizes', 'activation_functions',
                            'regularization_strength', 'learning_rates'
                        ],
                        default=['layer_count', 'layer_sizes'],
                        help="Parameters to search during architecture optimization",
                        key=f"{key_prefix}_search_space"
                    )
                
                config["complexity_preference"] = st.selectbox(
                    "Complexity Preference:",
                    options=['minimal', 'moderate', 'high', 'adaptive'],
                    index=3,
                    help="Preferred model complexity level",
                    key=f"{key_prefix}_complexity_preference"
                )
                
                st.markdown("---")
                
                # Deployment Strategy
                st.markdown("**üöÄ Deployment Strategy**")
                
                config["deployment_target"] = st.selectbox(
                    "Deployment Target:",
                    options=['development', 'staging', 'production', 'research'],
                    index=0,
                    help="Target deployment environment",
                    key=f"{key_prefix}_deployment_target"
                )
                
                config["scalability_requirements"] = st.selectbox(
                    "Scalability Requirements:",
                    options=['low', 'medium', 'high', 'enterprise'],
                    index=1,
                    help="Expected scaling requirements",
                    key=f"{key_prefix}_scalability_requirements"
                )
                
                config["monitoring_level"] = st.selectbox(
                    "Monitoring Level:",
                    options=['basic', 'standard', 'comprehensive', 'enterprise'],
                    index=1,
                    help="Level of model monitoring and tracking",
                    key=f"{key_prefix}_monitoring_level"
                )
                
                # Strategy Validation
                if st.button("üîç Validate Strategy", key=f"{key_prefix}_validate_strategy"):
                    validation_results = self._validate_strategy_configuration(config)
                    
                    if validation_results['valid']:
                        st.success("‚úÖ Strategy configuration is valid!")
                        st.info(f"üí° Recommendation: {validation_results['recommendation']}")
                    else:
                        st.warning(f"‚ö†Ô∏è Strategy issues detected: {validation_results['issues']}")
                        st.info(f"üí° Suggestion: {validation_results['suggestion']}")
            
            # ==================== ANALYSIS TAB ====================
            with analysis_tab:
                st.markdown("**Analysis Configuration**")
                
                config["enable_analysis"] = st.checkbox(
                    "Enable Advanced Analysis",
                    value=self.config['enable_analysis'],
                    help="Enable comprehensive neural network analysis",
                    key=f"{key_prefix}_enable_analysis"
                )
                
                if config["enable_analysis"]:
                    config["enable_convergence_monitoring"] = st.checkbox(
                        "Convergence Monitoring",
                        value=self.config.get('enable_convergence_monitoring', True),
                        help="Monitor training convergence",
                        key=f"{key_prefix}_convergence"
                    )
                    
                    config["enable_architecture_search"] = st.checkbox(
                        "Architecture Search",
                        value=self.config.get('enable_architecture_search', False),
                        help="Search for optimal architecture",
                        key=f"{key_prefix}_arch_search"
                    )
                    
                    config["performance_threshold"] = st.slider(
                        "Performance Threshold:",
                        min_value=0.1,
                        max_value=0.95,
                        value=self.config.get('performance_threshold', 0.7),
                        step=0.05,
                        help="Minimum acceptable performance",
                        key=f"{key_prefix}_perf_threshold"
                    )
            
            # ==================== VISUALIZATION TAB ====================
            with viz_tab:
                st.markdown("**Visualization Settings**")
                
                config["enable_display"] = st.checkbox(
                    "Enable Visualizations",
                    value=self.config['enable_display'],
                    help="Enable comprehensive visualizations",
                    key=f"{key_prefix}_enable_display"
                )
                
                if config["enable_display"]:
                    config["plot_training_progress"] = st.checkbox(
                        "Plot Training Progress",
                        value=self.config.get('plot_training_progress', True),
                        help="Generate training progress plots",
                        key=f"{key_prefix}_plot_progress"
                    )
                    
                    config["interactive_mode"] = st.checkbox(
                        "Interactive Plots",
                        value=self.config.get('interactive_mode', False),
                        help="Generate interactive Plotly visualizations",
                        key=f"{key_prefix}_interactive"
                    )
                    
                    config["save_plots"] = st.checkbox(
                        "Save Plots",
                        value=self.config.get('save_plots', True),
                        help="Automatically save generated plots",
                        key=f"{key_prefix}_save_plots"
                    )
            
            # Convert random_state to None if using default
            if config["random_state"] == 42:
                config["random_state"] = None
            
            return config
            
        except ImportError:
            # Fallback when streamlit is not available
            return {
                "hidden_layer_sizes": self.config['hidden_layer_sizes'],
                "activation": self.config['activation'],
                "solver": self.config['solver'],
                "alpha": self.config['alpha'],
                "learning_rate_init": self.config['learning_rate_init'],
                "max_iter": self.config['max_iter'],
                "random_state": self.config['random_state'],
                "enable_analysis": self.config['enable_analysis'],
                "enable_display": self.config['enable_display'],
                # Strategy defaults
                "strategy_profile": "balanced",
                "training_strategy": "standard",
                "performance_target": "balanced",
                "deployment_target": "development"
            }
    
    def _get_strategy_recommendations(self, profile: str) -> Dict[str, Any]:
        """Get strategy recommendations based on selected profile."""
        strategies = {
            'conservative': {
                'name': 'üõ°Ô∏è Conservative Strategy',
                'description': 'Prioritizes stability and reliability over performance. Ideal for production environments where consistency is critical.',
                'recommended_for': [
                    'Production systems',
                    'Risk-averse environments',
                    'Regulated industries',
                    'Critical applications'
                ],
                'features': [
                    'Lower learning rates',
                    'Strong regularization',
                    'Early stopping enabled',
                    'Extensive validation'
                ],
                'config_adjustments': {
                    'learning_rate_init': 0.0001,
                    'alpha': 0.001,
                    'early_stopping': True,
                    'validation_fraction': 0.2
                }
            },
            'balanced': {
                'name': '‚öñÔ∏è Balanced Strategy',
                'description': 'Optimal balance between performance and stability. Suitable for most general-purpose applications.',
                'recommended_for': [
                    'General applications',
                    'Proof of concepts',
                    'Standard regression tasks',
                    'Initial model development'
                ],
                'features': [
                    'Moderate parameters',
                    'Balanced regularization',
                    'Standard validation',
                    'Good convergence'
                ],
                'config_adjustments': {
                    'learning_rate_init': 0.001,
                    'alpha': 0.0001,
                    'early_stopping': False,
                    'max_iter': 200
                }
            },
            'aggressive': {
                'name': 'üöÄ Aggressive Strategy',
                'description': 'Maximizes performance and learning speed. Best for research and when computational resources are abundant.',
                'recommended_for': [
                    'Research projects',
                    'Performance optimization',
                    'Large datasets',
                    'Computational experiments'
                ],
                'features': [
                    'Higher learning rates',
                    'Minimal regularization',
                    'Extended training',
                    'Maximum performance'
                ],
                'config_adjustments': {
                    'learning_rate_init': 0.01,
                    'alpha': 0.00001,
                    'max_iter': 500,
                    'early_stopping': False
                }
            },
            'exploration': {
                'name': 'üîç Exploration Strategy',
                'description': 'Designed for discovering optimal architectures and hyperparameters through systematic exploration.',
                'recommended_for': [
                    'Hyperparameter tuning',
                    'Architecture search',
                    'Model selection',
                    'Research exploration'
                ],
                'features': [
                    'Architecture search enabled',
                    'Multiple configurations',
                    'Comprehensive analysis',
                    'Detailed reporting'
                ],
                'config_adjustments': {
                    'enable_analysis': True,
                    'enable_architecture_search': True,
                    'auto_optimize': True,
                    'optimization_budget': 'high'
                }
            },
            'production': {
                'name': 'üè≠ Production Strategy',
                'description': 'Optimized for production deployment with focus on reliability, monitoring, and maintainability.',
                'recommended_for': [
                    'Production deployment',
                    'Business applications',
                    'Scalable systems',
                    'Enterprise solutions'
                ],
                'features': [
                    'Stability focused',
                    'Comprehensive monitoring',
                    'Deployment ready',
                    'Enterprise features'
                ],
                'config_adjustments': {
                    'early_stopping': True,
                    'validation_fraction': 0.15,
                    'save_artifacts': True,
                    'monitoring_level': 'comprehensive'
                }
            },
            'research': {
                'name': 'üî¨ Research Strategy',
                'description': 'Configured for academic research with extensive analysis, visualization, and experimental features.',
                'recommended_for': [
                    'Academic research',
                    'Scientific studies',
                    'Algorithm development',
                    'Publication preparation'
                ],
                'features': [
                    'Full analysis suite',
                    'Advanced visualizations',
                    'Detailed logging',
                    'Research tools'
                ],
                'config_adjustments': {
                    'enable_analysis': True,
                    'enable_display': True,
                    'save_plots': True,
                    'interactive_mode': True
                }
            },
            'custom': {
                'name': 'üõ†Ô∏è Custom Strategy',
                'description': 'Fully customizable strategy for specific use cases and unique requirements.',
                'recommended_for': [
                    'Specialized applications',
                    'Unique requirements',
                    'Expert users',
                    'Custom workflows'
                ],
                'features': [
                    'Full customization',
                    'Manual configuration',
                    'Expert control',
                    'Flexible options'
                ],
                'config_adjustments': {}
            }
        }
        
        return strategies.get(profile, strategies['balanced'])
    
    def _validate_strategy_configuration(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Validate the strategy configuration and provide recommendations."""
        issues = []
        suggestions = []
        
        # Check for conflicting settings
        if config.get('performance_target') == 'speed_focused' and config.get('quality_threshold', 0) > 0.8:
            issues.append("High quality threshold conflicts with speed-focused target")
            suggestions.append("Consider lowering quality threshold or changing performance target")
        
        if config.get('deployment_target') == 'production' and not config.get('early_stopping', False):
            issues.append("Production deployment should use early stopping")
            suggestions.append("Enable early stopping for production stability")
        
        if config.get('architecture_approach') == 'automated_search' and config.get('training_strategy') == 'standard':
            issues.append("Automated architecture search works better with iterative training")
            suggestions.append("Consider using 'iterative_improvement' training strategy")
        
        # Generate recommendation
        if config.get('strategy_profile') == 'conservative':
            recommendation = "Conservative strategy selected - prioritizing stability and reliability"
        elif config.get('strategy_profile') == 'aggressive':
            recommendation = "Aggressive strategy selected - maximizing performance and learning speed"
        elif config.get('deployment_target') == 'production':
            recommendation = "Production deployment detected - ensure robust validation and monitoring"
        else:
            recommendation = "Balanced configuration - good for general-purpose applications"
        
        return {
            'valid': len(issues) == 0,
            'issues': issues,
            'suggestion': suggestions[0] if suggestions else "Configuration looks good",
            'recommendation': recommendation
        }
    
    # ==================== OPTIONAL MLPLUGIN METHODS ====================
    
    def get_category(self) -> str:
        """Get the algorithm category."""
        return "Neural Network"
    
    def preprocess_data(self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]) -> Tuple[Union[np.ndarray, pd.DataFrame], Union[np.ndarray, pd.Series]]:
        """Optional data preprocessing."""
        # The core component handles preprocessing internally
        return X, y
    
    def is_compatible_with_data(self, df: pd.DataFrame, target_column: str) -> Tuple[bool, str]:
        """Check if algorithm is compatible with the data."""
        try:
            if target_column not in df.columns:
                return False, f"Target column '{target_column}' not found in data"
            
            # Get features and target
            X = df.drop(columns=[target_column])
            y = df[target_column]
            
            # Check if target is numeric (regression)
            if not pd.api.types.is_numeric_dtype(y):
                return False, "Target must be numeric for regression"
            
            # Check minimum samples
            if len(df) < self._min_samples_required:
                return False, f"Requires at least {self._min_samples_required} samples, got {len(df)}"
            
            # Check for missing values in target
            if y.isnull().any():
                return False, "Target column contains missing values"
            
            # Check features
            if X.shape[1] == 0:
                return False, "No feature columns found"
            
            # Check for too many missing values in features
            missing_ratio = X.isnull().sum().sum() / (X.shape[0] * X.shape[1])
            if missing_ratio > 0.5:
                return False, f"Too many missing values in features ({missing_ratio:.1%})"
            
            return True, f"Compatible with {len(df)} samples and {X.shape[1]} features"
            
        except Exception as e:
            return False, f"Compatibility check failed: {str(e)}"
    
    # ==================== EXISTING MLPLUGIN INTERFACE ====================
    
    def get_plugin_info(self) -> Dict[str, Any]:
        """Get plugin information for the ML framework (Required by MLPlugin)."""
        return {
            'name': 'mlp_regressor',
            'display_name': 'Multi-layer Perceptron Regressor',
            'version': '2.0',
            'algorithm_type': 'Neural Network',
            'task_type': 'Regression',
            'description': 'Advanced Multi-layer Perceptron regression with comprehensive analysis and optimization',
            'parameters': {
                'hidden_layer_sizes': {'type': 'tuple', 'default': (100,), 'description': 'Hidden layer architecture'},
                'activation': {'type': 'str', 'default': 'relu', 'choices': ['relu', 'tanh', 'logistic', 'identity']},
                'solver': {'type': 'str', 'default': 'adam', 'choices': ['adam', 'lbfgs', 'sgd']},
                'alpha': {'type': 'float', 'default': 0.0001, 'description': 'L2 regularization strength'},
                'max_iter': {'type': 'int', 'default': 200, 'description': 'Maximum training iterations'}
            },
            'capabilities': {
                'training': True,
                'prediction': True,
                'analysis': True,
                'visualization': True,
                'reporting': True,
                'hyperparameter_optimization': True,
                'architecture_analysis': True,
                'convergence_monitoring': True
            },
            'requirements': {
                'min_samples': 10,
                'handles_missing_values': False,
                'requires_scaling': True,
                'memory_intensive': True,
                'supports_large_datasets': True
            }
        }
    
    def train(self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series], **kwargs) -> Dict[str, Any]:
        """Train the model (Required by MLPlugin)."""
        return self.fit(X, y, **kwargs)
    
    def evaluate(self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]) -> Dict[str, Any]:
        """Evaluate the model (Required by MLPlugin)."""
        try:
            if not self.is_trained:
                return {'error': 'Model must be trained before evaluation'}
            
            # Get predictions
            predictions = self.predict(X)
            if isinstance(predictions, dict) and 'error' in predictions:
                return predictions
            
            # Calculate metrics
            y_array = self._convert_to_array(y).flatten()
            score = self.score(X, y)
            
            mse = mean_squared_error(y_array, predictions)
            mae = mean_absolute_error(y_array, predictions)
            
            return {
                'r2_score': float(score),
                'mse': float(mse),
                'mae': float(mae),
                'rmse': float(np.sqrt(mse)),
                'n_samples': len(y_array),
                'model_complexity': len(self.config['hidden_layer_sizes'])
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def get_model_summary(self) -> Dict[str, Any]:
        """Get model summary (Required by MLPlugin)."""
        return self._create_model_summary()
    
    # ==================== MAIN PLUGIN INTERFACE ====================
    
    def fit(self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series], **kwargs) -> Dict[str, Any]:
        """
        Train the MLP model with comprehensive analysis and monitoring.
        
        Parameters:
        -----------
        X : array-like of shape (n_samples, n_features)
            Training features
        y : array-like of shape (n_samples,)
            Training targets
        **kwargs : dict
            Additional training parameters
            
        Returns:
        --------
        Dict[str, Any]
            Comprehensive training results
        """
        try:
            logger.info("üöÄ Starting MLP model training...")
            start_time = time.time()
            
            # Convert inputs if necessary
            X_array = self._convert_to_array(X)
            y_array = self._convert_to_array(y).flatten()
            
            # Validate inputs
            validation_result = self._validate_inputs(X_array, y_array)
            if not validation_result['valid']:
                return {'success': False, 'error': validation_result['error']}
            
            # Initialize core components
            self._initialize_components()
            
            # Prepare training configuration
            training_config = {**self.config, **kwargs}
            
            # Split data for validation if early stopping is enabled
            if training_config.get('early_stopping', False):
                X_train, X_val, y_train, y_val = train_test_split(
                    X_array, y_array, 
                    test_size=training_config.get('validation_fraction', 0.1),
                    random_state=training_config.get('random_state')
                )
            else:
                X_train, y_train = X_array, y_array
                X_val, y_val = None, None
            
            # Train the core model
            logger.info("üîÑ Training core MLP model...")
            core_results = self.mlp_core.train_model(X_train, y_train, X_val, y_val)
            
            if not core_results.get('model_fitted', False):
                raise RuntimeError("Core model training failed")
            
            # Store core training results
            self.training_results = {
                'core_results': core_results,
                'training_time': time.time() - start_time,
                'data_info': validation_result,
                'final_score': core_results.get('final_score', 0),
                'converged': core_results.get('converged', False),
                'n_iterations': core_results.get('n_iter', 0)
            }
            
            # Run advanced analysis if enabled
            if self.config['enable_analysis'] and self.mlp_analysis:
                logger.info("üî¨ Running advanced analysis...")
                try:
                    analysis_results = self._run_comprehensive_analysis(X_array, y_array)
                    self.analysis_results = analysis_results
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Analysis failed: {str(e)}")
                    self.analysis_results = {'error': str(e)}
            
            # Generate visualizations if enabled
            if self.config['enable_display'] and self.mlp_display:
                logger.info("üìä Generating visualizations...")
                try:
                    self._generate_training_visualizations(X_array, y_array)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Visualization generation failed: {str(e)}")
            
            # Mark as trained
            self.is_trained = True
            self.training_results['total_training_time'] = time.time() - start_time
            
            # Store training history
            training_record = {
                'timestamp': pd.Timestamp.now(),
                'data_shape': X_array.shape,
                'training_result': self.training_results,
                'parameters': self.get_params(),
                'config': training_config
            }
            self.training_history.append(training_record)
            
            logger.info(f"‚úÖ MLP training completed successfully in {self.training_results['total_training_time']:.2f}s")
            logger.info(f"üìä Final Score: {self.training_results['final_score']:.4f}")
            
            return {
                'success': True,
                'training_result': self.training_results,
                'model_summary': self._create_model_summary()
            }
            
        except Exception as e:
            logger.error(f"‚ùå MLP training failed: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'training_time': time.time() - start_time if 'start_time' in locals() else 0
            }
    
    def predict(self, X: Union[np.ndarray, pd.DataFrame]) -> Union[np.ndarray, Dict[str, Any]]:
        """
        Make predictions with the trained model.
        
        Parameters:
        -----------
        X : array-like of shape (n_samples, n_features)
            Test features
            
        Returns:
        --------
        np.ndarray or Dict[str, Any]
            Predictions or error information
        """
        try:
            if not self.is_trained or self.mlp_core is None:
                return {'error': 'Model must be trained before making predictions'}
            
            logger.info(f"üîÆ Making predictions for {X.shape[0]} samples...")
            
            X_array = self._convert_to_array(X)
            predictions = self.mlp_core.predict(X_array)
            
            # Store for analysis
            self.last_predictions = predictions
            
            logger.info("‚úÖ Predictions completed successfully")
            return predictions
            
        except Exception as e:
            logger.error(f"‚ùå Prediction failed: {str(e)}")
            return {'error': str(e)}
    
    def score(self, X: Union[np.ndarray, pd.DataFrame], y: Union[np.ndarray, pd.Series]) -> float:
        """
        Calculate R¬≤ score on test data.
        
        Parameters:
        -----------
        X : array-like of shape (n_samples, n_features)
            Test features
        y : array-like of shape (n_samples,)
            Test targets
            
        Returns:
        --------
        float
            R¬≤ score
        """
        try:
            if not self.is_trained:
                logger.warning("‚ö†Ô∏è Model not trained, returning 0 score")
                return 0.0
            
            predictions = self.predict(X)
            if isinstance(predictions, dict) and 'error' in predictions:
                return 0.0
            
            y_array = self._convert_to_array(y).flatten()
            score = r2_score(y_array, predictions)
            
            logger.info(f"üìä Model score (R¬≤): {score:.4f}")
            return float(score)
            
        except Exception as e:
            logger.error(f"‚ùå Scoring failed: {str(e)}")
            return 0.0
    
    # ==================== PARAMETER MANAGEMENT ====================
    
    def get_params(self) -> Dict[str, Any]:
        """Get model parameters."""
        return {
            'hidden_layer_sizes': self.config['hidden_layer_sizes'],
            'activation': self.config['activation'],
            'solver': self.config['solver'],
            'alpha': self.config['alpha'],
            'learning_rate_init': self.config['learning_rate_init'],
            'max_iter': self.config['max_iter'],
            'random_state': self.config['random_state'],
            'enable_analysis': self.config['enable_analysis'],
            'enable_display': self.config['enable_display']
        }
    
    def set_params(self, **params) -> 'MLPRegressorPlugin':
        """Set model parameters."""
        for param, value in params.items():
            if param in self.config:
                self.config[param] = value
            else:
                logger.warning(f"‚ö†Ô∏è Unknown parameter: {param}")
        
        # If model was trained, it needs retraining with new parameters
        if self.is_trained:
            logger.info("üîÑ Parameters changed - model needs retraining")
            self.is_trained = False
            self.mlp_core = None
            self.mlp_analysis = None
            self.mlp_display = None
        
        return self
    
    # ==================== UTILITY METHODS ====================
    
    def _convert_to_array(self, data: Union[np.ndarray, pd.DataFrame, pd.Series]) -> np.ndarray:
        """Convert various data types to numpy array."""
        try:
            if isinstance(data, pd.DataFrame):
                return data.values.astype(np.float64)
            elif isinstance(data, pd.Series):
                return data.values.astype(np.float64)
            elif isinstance(data, np.ndarray):
                return data.astype(np.float64)
            elif isinstance(data, (list, tuple)):
                return np.array(data, dtype=np.float64)
            else:
                return np.array(data, dtype=np.float64)
        except Exception as e:
            logger.error(f"‚ùå Data conversion failed: {str(e)}")
            raise ValueError(f"Could not convert data to array: {str(e)}")
    
    def _validate_inputs(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """Validate input data."""
        try:
            # Check shapes
            if X.ndim != 2:
                return {'valid': False, 'error': f'X must be 2D, got {X.ndim}D'}
            
            if y.ndim != 1:
                return {'valid': False, 'error': f'y must be 1D, got {y.ndim}D'}
            
            if X.shape[0] != y.shape[0]:
                return {'valid': False, 'error': f'X and y must have same number of samples: {X.shape[0]} vs {y.shape[0]}'}
            
            # Check for sufficient samples
            if X.shape[0] < self._min_samples_required:
                return {'valid': False, 'error': f'Need at least {self._min_samples_required} samples, got {X.shape[0]}'}
            
            # Check for NaN/inf values
            if np.any(np.isnan(X)) or np.any(np.isinf(X)):
                return {'valid': False, 'error': 'X contains NaN or infinite values'}
            
            if np.any(np.isnan(y)) or np.any(np.isinf(y)):
                return {'valid': False, 'error': 'y contains NaN or infinite values'}
            
            return {
                'valid': True,
                'n_samples': X.shape[0],
                'n_features': X.shape[1],
                'data_quality': 'good'
            }
            
        except Exception as e:
            return {'valid': False, 'error': f'Validation failed: {str(e)}'}
    
    def _initialize_components(self):
        """Initialize core components based on configuration."""
        try:
            # Initialize core MLP
            if self.mlp_core is None:
                self.mlp_core = MLPCore(**self.config)
                logger.info("‚úÖ MLPCore initialized")
            
            # Initialize analysis component
            if self.config['enable_analysis'] and self.mlp_analysis is None:
                self.mlp_analysis = MLPAnalysis(self.mlp_core)
                logger.info("‚úÖ MLPAnalysis initialized")
            
            # Initialize display component
            if self.config['enable_display'] and self.mlp_display is None:
                self.mlp_display = MLPDisplay(self.mlp_core, self.mlp_analysis)
                logger.info("‚úÖ MLPDisplay initialized")
                
        except Exception as e:
            logger.error(f"‚ùå Component initialization failed: {str(e)}")
            raise
    
    def _run_comprehensive_analysis(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """Run comprehensive analysis."""
        try:
            analysis_results = {}
            
            # Network complexity analysis
            complexity_analysis = self.mlp_analysis.analyze_network_complexity()
            analysis_results['complexity_analysis'] = complexity_analysis
            
            # Training issues detection
            training_issues = self.mlp_analysis.detect_training_issues()
            analysis_results['training_issues'] = training_issues
            
            # Generalization analysis
            generalization_analysis = self.mlp_analysis.analyze_generalization_performance(X, y)
            analysis_results['generalization_analysis'] = generalization_analysis
            
            return analysis_results
            
        except Exception as e:
            return {'error': str(e)}
    
    def _generate_training_visualizations(self, X: np.ndarray, y: np.ndarray):
        """Generate training visualizations."""
        try:
            if not self.config['save_plots']:
                return
            
            artifact_dir = Path(self.config['artifact_dir'])
            artifact_dir.mkdir(parents=True, exist_ok=True)
            
            # Generate and save plots
            plots_saved = self.mlp_display.save_all_plots(X, y, str(artifact_dir))
            self.training_results['saved_plots'] = plots_saved
            
        except Exception as e:
            logger.warning(f"Visualization generation failed: {e}")
    
    def _create_model_summary(self) -> Dict[str, Any]:
        """Create comprehensive model summary."""
        try:
            summary = {
                'algorithm': 'Multi-layer Perceptron Regressor',
                'version': self._plugin_info['version'],
                'status': 'trained' if self.is_trained else 'not_trained',
                'parameters': self.get_params(),
                'training_info': {},
                'performance_info': {}
            }
            
            if self.is_trained and self.training_results:
                summary['training_info'].update({
                    'training_samples': self.training_results.get('data_info', {}).get('n_samples', 0),
                    'n_features': self.training_results.get('data_info', {}).get('n_features', 0),
                    'training_time': self.training_results.get('total_training_time', 0),
                    'converged': self.training_results.get('converged', False),
                    'iterations': self.training_results.get('n_iterations', 0)
                })
                
                summary['performance_info'].update({
                    'final_score': self.training_results.get('final_score', 0),
                    'analysis_available': bool(self.analysis_results),
                    'visualizations_generated': 'saved_plots' in self.training_results
                })
            
            summary['capabilities'] = {
                'supports_regression': True,
                'supports_classification': False,
                'handles_missing_values': False,
                'automatic_scaling': True,
                'hyperparameter_optimization': True,
                'architecture_analysis': True
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå Model summary creation failed: {str(e)}")
            return {'error': str(e)}
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get comprehensive model information."""
        info = {
            'plugin_info': self._plugin_info,
            'is_trained': self.is_trained,
            'parameters': self.get_params(),
            'training_history_count': len(self.training_history),
            'capabilities': {
                'neural_network_training': True,
                'hyperparameter_optimization': True,
                'architecture_analysis': True,
                'convergence_monitoring': True,
                'interactive_visualization': True,
                'comprehensive_reporting': True
            }
        }
        
        if self.is_trained:
            info.update({
                'model_summary': self._create_model_summary(),
                'training_results': self.training_results,
                'analysis_results': self.analysis_results
            })
        
        return info
    
    def __repr__(self) -> str:
        """String representation of the MLP Plugin."""
        status = "trained" if self.is_trained else "not trained"
        layers = str(self.config['hidden_layer_sizes'])
        return (f"MLPRegressorPlugin(hidden_layer_sizes={layers}, "
                f"activation='{self.config['activation']}', solver='{self.config['solver']}', "
                f"status={status})")


# Factory function - THIS WAS MISSING!
def get_plugin():
    """Factory function to get the plugin instance (Required by MLPlugin system)"""
    return MLPRegressorPlugin()

# ==================================================================================
# END OF MLP REGRESSOR PLUGIN
# ==================================================================================

"""
üß† MLP Regressor Plugin Completion Summary:

‚úÖ Fixed Critical Issues:
   - Added missing factory function get_plugin() 
   - Implemented all required abstract methods from MLPlugin
   - Fixed interface compatibility with MLPlugin system
   - Proper error handling and validation

‚úÖ Required MLPlugin Methods Implemented:
   - get_name(): Algorithm name
   - get_description(): Algorithm description  
   - create_model_instance(): Instance creation with hyperparameters
   - get_hyperparameter_config(): UI configuration
   - get_plugin_info(): Plugin metadata
   - train(): Training interface
   - evaluate(): Model evaluation
   - get_model_summary(): Model summary

‚úÖ Enhanced Plugin Features:
   - Comprehensive neural network training
   - Advanced analysis and optimization capabilities
   - Professional visualization suite
   - Robust error handling and logging
   - Training history and persistence

‚úÖ Integration Benefits:
   - Full compatibility with MLPlugin framework
   - Consistent interface with other plugins
   - Professional parameter management
   - Comprehensive validation and preprocessing

üöÄ Now ready for seamless integration into the ML framework!
"""